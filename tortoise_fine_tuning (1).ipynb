{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading a high-quality TTS dataset for German language (LibriTTS-style dataset)"
      ],
      "metadata": {
        "id": "--ewOjx2wqnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HUI-Audio-Corpus-German: A high quality TTS dataset (https://arxiv.org/pdf/2106.06309.pdf)\n",
        "!wget https://opendata.iisys.de/opendata/Datasets/HUI-Audio-Corpus-German/dataset_clean/others_Clean.zip"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "15uTrv0_wqn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip dataset"
      ],
      "metadata": {
        "id": "8jXNySIXwqn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./others_Clean.zip -d ./dataset"
      ],
      "metadata": {
        "id": "bAEp8Nojwqn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust dataset structure so that all train and val wav files are located in an individual folder"
      ],
      "metadata": {
        "id": "TKKhd4UDwqn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import csv\n",
        "\n",
        "transcribed_audio_samples = []\n",
        "\n",
        "for folder in glob(\"others_dataset/*\"):\n",
        "  for subfolder in glob(f\"{folder}/*\"):\n",
        "    with open(f\"{subfolder}/metadata.csv\") as csv_file:\n",
        "        audio_samples = csv.reader(csv_file, delimiter='\\n')\n",
        "        for audio_sample in audio_samples:\n",
        "            transcribed_audio_sample = ''.join(audio_sample)\n",
        "            filename, transcription = transcribed_audio_sample.split('|')\n",
        "            new_transcribed_audio_sample = f\"wavs/{filename}.wav|{transcription}\"\n",
        "            transcribed_audio_samples.append((f\"{subfolder}/wavs/{filename}.wav\", new_transcribed_audio_sample))"
      ],
      "metadata": {
        "id": "qV-fod-awqn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divide dataset into train and val subsets"
      ],
      "metadata": {
        "id": "VjdHbeAlwqn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(all_transcribed_audio_samples)\n",
        "num_train_samples = int(len(all_transcribed_audio_samples) * 0.85)\n",
        "\n",
        "train_dataset = transcribed_audio_samples[:num_train_samples]\n",
        "val_dataset = transcribed_audio_samples[num_train_samples:]"
      ],
      "metadata": {
        "id": "UWyNZCR4wqn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy files to train and val folders"
      ],
      "metadata": {
        "id": "87BT5Qqawqn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!mkdir dataset/wavs"
      ],
      "metadata": {
        "id": "DGpyDlIrwqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "train_val_list = [('train', train_dataset), ('val', val_dataset)]\n",
        "\n",
        "for stage, dataset in train_val_list:\n",
        "    sample_list = []\n",
        "    for old_sample, new_sample in dataset:\n",
        "        # copy audio sample to new location\n",
        "        shutil.copyfile(old_sample, \"./dataset/\" + new_sample.split(\"|\")[0])\n",
        "        sample_list.append(new_sample)\n",
        "\n",
        "    with open(f\"./dataset/{stage}.txt\", \"w\") as sample_file:\n",
        "        sample_file.write(\"\\n\".join(sample_list))"
      ],
      "metadata": {
        "id": "Q_eJ1R7pwqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip altered dataset"
      ],
      "metadata": {
        "id": "HTEn1SQtwqn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r hui_audio_corpus.zip ./dataset"
      ],
      "metadata": {
        "id": "-q9UxgEzwqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alter fine-tuning code to allow special letters (e.g. ä,ö,ü,ß for German language)\n",
        "---\n",
        "##### Source: https://github.com/152334H/DL-Art-School\n",
        "##### File: codes/models/audio/tts/tacotron2/text/cleaners.py\n",
        "- Alter method english_cleaners to clean input text for your language (line 83)\n",
        "\n",
        "##### File: codes/models/audio/tts/tacotron2/text/symbols.py\n",
        "- Add special characters to \\_letters (line 12)\n",
        "\n",
        "##### Create File: experiments/custom_language_gpt.yml\n",
        "- Copy file experiments/EXAMPLE_gpt.yml and rename it to custom_language_gpt.yml\n",
        "- Change experiment name to custom_language_gpt (line 1)\n",
        "- Change name to train_dataset (line 14)\n",
        "- Change path to ../../dataset/train.txt (line 18)\n",
        "- Add attribute *tokenizer_vocab: ../custom_language_tokenizer.json* (line 29)\n",
        "- Change name to val_dataset (line 31)\n",
        "- Change path to ../../dataset/val.txt (line 35)\n",
        "- Add attribute *tokenizer_vocab: ../custom_language_tokenizer.json* (line 46)\n",
        "- Change value to 5000 (line 128)\n",
        "\n",
        "##### File: .gitignore\n",
        "- Add statement *!experiments/custom_language_gpt.yml* (line 169)\n",
        "\n",
        "##### File: codes/requirements.laxed.txt\n",
        "- Change transformers to transformers==4.29.2 (line 39)\n",
        "\n",
        "##### File: codes/utils/util.py\n",
        "- Change to *from torch import inf* (line 25)"
      ],
      "metadata": {
        "id": "nfKOTk4ywqn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install all required modules and clone repo with altered fine-tuning code"
      ],
      "metadata": {
        "id": "P5LYvd1awqn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thisserand/DL-Art-School\n",
        "%cd DL-Art-School/codes/\n",
        "!pip install -r requirements.laxed.txt"
      ],
      "metadata": {
        "id": "inq8ZbLSwqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download model weights for the VQ-VAE and Autoregressive Model (GPT-2)"
      ],
      "metadata": {
        "id": "vViFPS27wqn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth -O ../experiments/dvae.pth\n",
        "!wget https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth -O ../experiments/autoregressive.pth"
      ],
      "metadata": {
        "id": "hYAL4Ma_wqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text file containing all transcriptions as source to train a tokenizer"
      ],
      "metadata": {
        "id": "Vs8fJqIiwqn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcriptions = \"\"\n",
        "dataset_path = \"../../dataset\"\n",
        "\n",
        "for stage in [\"train\", \"val\"]:\n",
        "    with open(f'{dataset_path}/{stage}.txt') as f:\n",
        "        for line in f.readlines():\n",
        "            transcriptions += ' ' + line.split(\"|\")[1].strip()\n",
        "\n",
        "with open(\"transcriptions.txt\", \"w\") as f:\n",
        "  f.write(transcriptions.strip())"
      ],
      "metadata": {
        "id": "X-7qoFmhwqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Tokenizer"
      ],
      "metadata": {
        "id": "-pa7D3YOwqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from german_transliterate.core import GermanTransliterate\n",
        "\n",
        "\n",
        "def text_cleaners(text):\n",
        "  ###########################################\n",
        "  # ToDo Adjust this code for your language #\n",
        "  ###########################################\n",
        "  text = GermanTransliterate().transliterate(text)\n",
        "  text = text.lower()\n",
        "  text = re.sub(re.compile(r'\\s+'), ' ', text)\n",
        "  text = text.replace('\"', '')\n",
        "  return text\n",
        "\n",
        "\n",
        "def remove_extraneous_punctuation(word):\n",
        "    replacement_punctuation = {\n",
        "        '{': '(', '}': ')',\n",
        "        '[': '(', ']': ')',\n",
        "        '`': '\\'', '—': '-',\n",
        "        '—': '-', '`': '\\'',\n",
        "        'ʼ': '\\''\n",
        "    }\n",
        "    replace = re.compile(\"|\".join([re.escape(k) for k in sorted(replacement_punctuation, key=len, reverse=True)]), flags=re.DOTALL)\n",
        "    word = replace.sub(lambda x: replacement_punctuation[x.group(0)], word)\n",
        "    extraneous = re.compile(r'^[@#%_=\\$\\^&\\*\\+\\\\]$')\n",
        "    word = extraneous.sub('', word)\n",
        "    return word\n",
        "\n",
        "with open('transcriptions.txt', 'r', encoding='utf-8') as at:\n",
        "    ttsd = at.readlines()\n",
        "    allowed_characters_re = re.compile(r'^[a-zäöüß!:;\"/, \\-\\(\\)\\.\\'\\?ʼ]+$')\n",
        "\n",
        "    def preprocess_word(word, report=False):\n",
        "        word = text_cleaners(word)\n",
        "        word = remove_extraneous_punctuation(word)\n",
        "        if not bool(allowed_characters_re.match(word)):\n",
        "            if report and word:\n",
        "                print(f\"REPORTING: '{word}'\")\n",
        "            return ''\n",
        "        return word\n",
        "\n",
        "    def batch_iterator(batch_size=1000):\n",
        "        print(\"Processing ASR texts.\")\n",
        "        for i in range(0, len(ttsd), batch_size):\n",
        "            yield [preprocess_word(t, True) for t in ttsd[i:i+batch_size]]\n",
        "\n",
        "    trainer = BpeTrainer(special_tokens=['[STOP]', '[UNK]', '[SPACE]'], vocab_size=255)\n",
        "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    tokenizer.train_from_iterator(batch_iterator(), trainer, length=len(ttsd))\n",
        "    tokenizer.save('../custom_language_tokenizer.json')"
      ],
      "metadata": {
        "id": "qDO0La4Hwqn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make sure the waveform audio has a sampling rate of 22.05kHz\n",
        "##### Install librosa using the following command (automatically installs soundfile as well):\n",
        "##### *pip install librosa*"
      ],
      "metadata": {
        "id": "DXzTTs2_wqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def resample_wav_file(input_file, target_sampling_rate=22050):\n",
        "    # Load audio file\n",
        "    audio, sampling_rate = librosa.load(input_file, sr=None)\n",
        "\n",
        "    # Check if the sampling rate matches the target\n",
        "    if sampling_rate != target_sampling_rate:\n",
        "\n",
        "        # Resample audio to the target sampling rate\n",
        "        audio_resampled = librosa.resample(audio, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
        "\n",
        "        # Overwrite the input file with the resampled audio\n",
        "        sf.write(input_file, audio_resampled, target_sampling_rate)\n",
        "\n",
        "# Resample all audio samples to 22.05kHz\n",
        "dataset_path = \"../../dataset/wavs/\"\n",
        "for wav_file in glob(dataset_path + \"*.wav\"):\n",
        "    resample_wav_file(input_file)"
      ],
      "metadata": {
        "id": "9IFVaZ0xwqn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tune the Autoregressive Model"
      ],
      "metadata": {
        "id": "PnMHDUGbwqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py -opt ../experiments/custom_language_gpt.yml"
      ],
      "metadata": {
        "id": "NB77xOOswqn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The fine-tuned autoregressive model can be found here:\n",
        "##### **/DL-Art-School/experiments/custom_language_gpt/models/**"
      ],
      "metadata": {
        "id": "FdSPPGuxwqn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload fine-tuned model to HuggingFace"
      ],
      "metadata": {
        "id": "oYTX_3BWwqn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "hf_user_name = \"\"\n",
        "repository_name = \"\"\n",
        "repo_id = f\"{hf_user_name}/{repository_name}\"\n",
        "fine_tuned_model_path = \"../experiments/custom_language_gpt/models/2500_gpt.pth\"\n",
        "hf_auth_token = \"\"\n",
        "\n",
        "\n",
        "api.create_repo(repo_id=repo_id, token=hf_auth_token, repo_type='model')\n",
        "\n",
        "model_url = api.upload_file(\n",
        "    path_or_fileobj=\"fine_tuned_model_path\",\n",
        "    path_in_repo=\"custom_language_gpt.pth\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        ")\n",
        "\n",
        "print(f\"The fine-tuned model was uploaded to: {model_url}\")"
      ],
      "metadata": {
        "id": "W_ujCh4vwqn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone adjusted inference code for German language"
      ],
      "metadata": {
        "id": "l0R6Q0WSSqKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://gitlab.com/tisserand13/tortoise-tts\n",
        "%cd tortoise-tts\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "njGCsV8dSiaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define example text and voice samples to assess generation quality"
      ],
      "metadata": {
        "id": "WMbr13alS0GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = [\"Das Trainieren von Sprachmodellen für neue Sprachen funktioniert äußerst gut!\",\n",
        "                 \"Äpfel und Birnen sind gesund für den Körper.\",\n",
        "                 \"Übermorgen fahren wir in die Berge.\",\n",
        "                 \"Das Café um die Ecke serviert köstlichen Kuchen und Kaffee.\",\n",
        "                 \"Ein leises Lachen verzaubert die Luft und lässt Herzen höher schlagen.\",\n",
        "                 \"Inmitten des Blütenmeers wandern wir durch den zauberhaften Frühlingswald.\"\n",
        "                ]\n",
        "\n",
        "voices = [\"tom\", \"train_atkins\", \"angie\", \"daniel\", \"deniro\", \"emma\"]"
      ],
      "metadata": {
        "id": "ZIveM1W6S8lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate speech"
      ],
      "metadata": {
        "id": "b0ICf9aJS-au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_voice\n",
        "import torchaudio\n",
        "import IPython\n",
        "\n",
        "tts = TextToSpeech(kv_cache=True)\n",
        "\n",
        "for voice, text in zip(voices, example_texts):\n",
        "    voice_samples, _ = load_voice(voice)\n",
        "    audio = tts.tts_with_preset(text, voice_samples=voice_samples, preset='fast')\n",
        "    torchaudio.save(f'{voice}.wav', audio.squeeze(0), 24000)\n",
        "    IPython.display.display(IPython.display.Audio(f'{voice}.wav'))"
      ],
      "metadata": {
        "id": "BreeYZiuTBua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "hop_length = 512\n",
        "db_threshold = -45\n",
        "\n",
        "def trim_audio(audio):\n",
        "    generated_audio = audio.squeeze().numpy()\n",
        "    audio_rms = librosa.feature.rms(y=generated_audio, frame_length=2048, hop_length=hop_length)[0]\n",
        "    audio_db = librosa.power_to_db(rmse**2, ref=np.max)\n",
        "\n",
        "    start_index, end_index = None, None\n",
        "    for index, frame_rms in enumerate(y_values):\n",
        "        if frame_rms >= db_threshold:\n",
        "            if start_index is None:\n",
        "                    start_index = index\n",
        "        elif start_index is not None:\n",
        "            end_index = index - 1\n",
        "            break\n",
        "\n",
        "    return audio.squeeze(0)[:, start_index*hop_length:end_index*hop_length]"
      ],
      "metadata": {
        "id": "9zuqHIlb4mEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}